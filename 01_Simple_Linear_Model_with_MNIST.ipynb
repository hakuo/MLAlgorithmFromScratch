{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Tutorial #01\n",
    "\n",
    "# Simple Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "- Training-set:\t\t55000\n",
      "- Validation-set:\t5000\n",
      "- Test-set:\t\t10000\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "from mnist import MNIST\n",
    "data = MNIST(data_dir='data/MNIST/')\n",
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(data.num_train))\n",
    "print(\"- Validation-set:\\t{}\".format(data.num_val))\n",
    "print(\"- Test-set:\\t\\t{}\".format(data.num_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store some data information\n",
    "# The number of pixels in each dimension of image\n",
    "img_size = None\n",
    "\n",
    "# The images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = None\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays\n",
    "img_shape = None\n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = None\n",
    "\n",
    "# Number of colour channels for the images: 1 channel for gray-scale.\n",
    "num_channels = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function for plotting images\n",
    "\n",
    "Function used to plot 9 images in a 3x3 grid, and writing the true and predicted classes below each images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testcase for plot_images function\n",
    "# Get the first 9 images from the test-set\n",
    "images = None\n",
    "\n",
    "# Get the true classes for those images.\n",
    "cls_true = None\n",
    "\n",
    "# Plot the images and labels using our helper-function above\n",
    "plot_images(images=images, cls_true=cls_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow graph\n",
    "\n",
    "Why using TensorFlow:\n",
    "\n",
    "- TensorFlow can be more efficient than NumPy because TensorFlow knows the entire computation graph, while NumPy only knows the computation of a single mathematical operation at a time.\n",
    "\n",
    "- TensorFlow can also automatically calculate the gradients needed to optimize the variables of the graph so as to make the model perform better (The gradient of entire graph can be calculated using chain-rule for derivatives)\n",
    "\n",
    "- TensorFlow takes advantages of multi-core CPUs as well as GPUs.\n",
    "\n",
    "A TensorFlow graph consists of the following parts which will be detailed below:\n",
    "\n",
    "- **Placeholder variables** used to feed input into the graph.\n",
    "- **Model variables** that are going to be optimized so far as to make the model perform better.\n",
    "- **Model** which is essentially just a mathematical function that calculates some output given the input in the **placeholder variables** and the **model variables**.\n",
    "- **Cost measure** that can be used to guide the optimization variables.\n",
    "- **An optimization method** which updates the variables of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder variables\n",
    "# Input image: size=img_size_flat\n",
    "x = None\n",
    "# Label: size=num_classes (one-hot encoder)\n",
    "y_true = None\n",
    "# True class of each image\n",
    "y_true_cls = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to be optimized\n",
    "# Weights: initialized with zeros and shape is (img_size_flat x num_classes)\n",
    "weights = None\n",
    "# Biases: 1-Dimensional tensor of length (num_classes)\n",
    "biases = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: Y = XW + B\n",
    "logits = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax: activation function\n",
    "y_pred = None\n",
    "# Archive max value of y_pred\n",
    "y_pred_cls = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost-function to be optimized\n",
    "\n",
    "To make the model better at classifying the input images, we must know somehow change the variable for `weights` and `biases`. To do this we first need to know how well the model currently performs by comparing the predicted output of the model `y_pred` and the desired output `y_true`.\n",
    "\n",
    "The cross-entropy is a performance measure used in classification. The cross-entropy is a continuous function that is always positive and if the predicted output of the model exactly matches the desired output then the cross-entropy equals to zero. The goal of optimization is to minimize the cross-entropy so it gets as close to zero as possible by changine the `weights` and `biases` of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost function: softmax_cross_entropy_with_logits_v2\n",
    "cross_entropy = None\n",
    "# Take the average of the cross-entropy for all image classifications\n",
    "cost = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization method: GradientDescentOptimizer\n",
    "optimizer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance measures\n",
    "\n",
    "We need a few more performance measures to display the progress to the user. This is a vector of booleans whether the predicted class equals the true class of each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare y_pred_cls - y_true_cls and return boolean\n",
    "correct_prediction = None\n",
    "\n",
    "# Calculate the classification accuracy by type-casting the booleans to floats: False-0 and True-1 \n",
    "# and then calculating the average of these numbers.\n",
    "accuracy = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorFlow session\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function to perform the optimization iterations\n",
    "\n",
    "There are 55000 images in the training-set. It takes a long time to calculate the gradient of the model using all these images. Therefore, we use Stochastic Gradient Descent (SGD) which only uses a small batch of images in each iteration of the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for performing a number of optimization iterations so as to gradually improve the `weights` and `biases` of the model. In each iteration, a new batch of data is selected from the training-set and then TensorFlow executes the optimizer using those training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(num_iterations):\n",
    "    for i in range(num_iterations):\n",
    "        # Get a batch of training examples.\n",
    "        # x_batch holds a batch of images,\n",
    "        # y_true_batch are the true labels for those images.\n",
    "        x_batch, y_true_batch, _ = data.random_batch(batch_size=batch_size)\n",
    "        \n",
    "        # Put the batch into a dict for placeholder variables in TensorFlow graph\n",
    "        # Note that the placeholder for y_true_cls is not set because it is not\n",
    "        # used during training.\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "        \n",
    "        # Run the optimizer using this batch of training data.\n",
    "        # TensorFlow assigns the variables in feed_dict_train to the placeholder\n",
    "        # variables and then run the optimizer.\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions to show performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict_test = {x: data.x_test,\n",
    "                  y_true: data.y_test,\n",
    "                  y_true_cls: data.y_test_cls}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy():\n",
    "    # Use TensorFlow to compute the accuracy\n",
    "    acc = session.run(accuracy, feed_dict=feed_dict_test)\n",
    "    print(\"Accuracy on test-set: {0:.1%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix():\n",
    "    # Get the true classification for the test-set.\n",
    "    cls_true = None\n",
    "    \n",
    "    # Get the predicted classification for the test-set.\n",
    "    cls_pred = None\n",
    "    \n",
    "    # Get the confusion matrix using sklearn.\n",
    "    cm = confusion_matrix(y_true=cls_true,\n",
    "                          y_pred=cls_pred)\n",
    "    print(cm)\n",
    "    \n",
    "    # Plor the confusion matrix as an image.\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    \n",
    "    # Make various adjustments to the plot.\n",
    "    plt.tight_layout()\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, range(num_classes))\n",
    "    plt.yticks(tick_marks, range(num_classes))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example_errors():\n",
    "    # Use TensorFlow to get a list of boolean values\n",
    "    # whether each test-image has been correctly classified,\n",
    "    # and a list for the predicted class of each image.\n",
    "    correct, cls_pred = session.run([correct_prediction, y_pred_cls],\n",
    "                                    feed_dict=feed_dict_test)\n",
    "    \n",
    "    # Negate the boolean array.\n",
    "    incorrect = None\n",
    "    \n",
    "    # Get the images from the test-set that have been incorrectly classified\n",
    "    images = None\n",
    "    \n",
    "    # Get predicted classed for those images.\n",
    "    cls_pred = None\n",
    "    \n",
    "    # Get the true classed for those images.\n",
    "    cls_true = None\n",
    "    \n",
    "    # Plot the first 9 images.\n",
    "    plot_images(images=images[0:9],\n",
    "                cls_true=cls_true[0:9],\n",
    "                cls_pred=cls_pred[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weights():\n",
    "    # Get the values for the weights from TensorFlow variable.\n",
    "    w = session.run(weights)\n",
    "    \n",
    "    # Get the lowest and highest values for the weights.\n",
    "    # This is used to correct the colour intensity across the images so they\n",
    "    # can be compared with each other.\n",
    "    w_min = np.min(w)\n",
    "    w_max = np.max(w)\n",
    "    \n",
    "    # Create figure with 3x4 sub-plots, where the last 2 sub-plots are unused.\n",
    "    fig, axes = plt.subplots(3,4)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Only use the weights for the first 10 sub-plots.\n",
    "        if i<10:\n",
    "            # Get the weights for the i'th digit and reshape it\n",
    "            # Note that w.shape == (img_size_flat, 10)\n",
    "            image = w[:,i].reshape(img_shape)\n",
    "            \n",
    "            # Set the label for the sub-plot.\n",
    "            ax.set_xlabel(\"Weights: {}\".format(i))\n",
    "            \n",
    "            # Plot the image\n",
    "            ax.imshow(image, vmin=w_min, vmax=w_max, cmap='seismic')\n",
    "        \n",
    "        # Remove ticks from each sub-plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots in a single Notebook cell.\n",
    "    plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After 1 optimization iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize(num_iterations=1)\n",
    "print_accuracy()\n",
    "print(\"Example errors:\")\n",
    "plot_example_errors()\n",
    "print(\"Weights\")\n",
    "plot_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After 10 optimization iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize(num_iterations=9)\n",
    "print_accuracy()\n",
    "print(\"Example errors:\")\n",
    "plot_example_errors()\n",
    "print(\"Weights\")\n",
    "plot_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After 1000 optimization iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize(num_iterations=990)\n",
    "print_accuracy()\n",
    "print(\"Example errors:\")\n",
    "plot_example_errors()\n",
    "print(\"Weights\")\n",
    "plot_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow GPU",
   "language": "python",
   "name": "tensorflow_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
